% THIS IS SIGPROC-SP.TEX - VERSION 3.1
% WORKS WITH V3.2SP OF ACM_PROC_ARTICLE-SP.CLS
% APRIL 2009
%
% It is an example file showing how to use the 'acm_proc_article-sp.cls' V3.2SP
% LaTeX2e document class file for Conference Proceedings submissions.
% ------------------------------------------------------------------------------
% This .tex file (and associated .cls V3.2SP) *DOES NOT* produce:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) Page numbering
% ------------------------------------------------------------------------------
% It is an example which *does* use the .bib file (from which the .bbl file
% is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission,
% you need to 'insert'  your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% Questions regarding SIGS should be sent to
% Adrienne Griscti ---> griscti@acm.org
%
% Questions/suggestions regarding the guidelines, .tex and .cls files, etc. to
% Gerald Murray ---> murray@hq.acm.org
%
% For tracking purposes - this is V3.1SP - APRIL 2009

\documentclass{acm_proc_article-sp}

\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}

\begin{document}

\title{On the Ground Validation of Online Diagnosis with Twitter and Medical Records}

%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{4} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
\alignauthor
Todd Bodnar\titlenote{Corresponding author}\\
       \affaddr{Pennsylvania State University}\\
\affaddr{Center for Infectious Disease \\Dynamics and Department \\of Biology}\\
 %      \affaddr{University Park, PA 16802}\\
       \email{meme@psu.edu}
\alignauthor
Vicki Barclay\\
\and 
\alignauthor
Conrad S Tucker\\
\affaddr{Pennsylvania State Univeristy}
\affaddr{Department of Engineering \\Design and Industrial and \\Manufacturing Engineering}
\email{conrad.tucker@psu.edu}
\alignauthor
Marcel Salath\'e\\
       \affaddr{Pennsylvania State University}\\
\affaddr{Center for Infectious Disease \\Dynamics and Department \\of Biology}\\
%       \affaddr{University Park, PA 16802}\\
       \email{salathe@psu.edu}
}

\maketitle
\begin{abstract}
This is an abstract
\end{abstract}

% A category with the (minimum) three required fields
%\category{I.6.4}{Simulation and Modeling}{Model Validation and Analysis}
\category{I.2.1}{Artificial Intelligence}{Applications and Expert Systems}[Medicine and Science]
%A category including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

\terms{Experimentation, Validation}

\keywords{Twitter, Validation, Digital Epidemiology, Remote Diagnosis} % NOT required for Proceedings

\section{Introduction}
%Digital epidemiology, datamining Internet records to approach epidemological questions in novel ways, has recently been proposed as an alternative to traditional disease surveillance methods[]. 

Disease surveillance systems -- traditionally relying on reports from medical practitioners -- are an important part of disease control. However, these traditional surveillance systems are often costly and slow to respond[].  The widespread adoption of the Internet by the general public has provided opertunities for the development of novel disease surveillance methods. Compared to traditional systems, where data is provided by medical diagnosis, these new systems provide either semi-automatic -- through long term self reporting systems[] -- or fully automatic -- through datamining search queries or social media -- disease surveillance. While these methods are cheaper, faster and cover a larger number of individuals than traditional systems, one can be less confident about their results than the results from a system based on professional diagnosis. In this paper, we develop a system that performs long term surveillance on Twitter users with methods trained on professionally diagnosed data that combines the advantages of all three of these previous systems.

Previous work with datamining social media has focused on methods to replicate the patterns found in traditional surveilance networks[]. However, these methods have several limitations. First, they generally do not differentiate between an individual with an illness and an individual that is worried about an illness[]. This may have resulted in a predicted influenza rate that was much higher then the actual 2013 influenza rate[]. Second, these methods cannot be extended to areas without a previous surveillance network. Finally, these methods are fundamentially incapapble of detecting diseases that do not show strong spatio-temporal patters such as mental illness, obesity or Parkinson's disease[]. Instead of top-down methods to measure levels of disease in a population, we approach this problem from the bottom-up. This addresses all three of these issues: we only diagnose individuals that are likely to have the disease, and not just interested in the disease; we do not require previous data when applying these methods to new problems or locations; and these methods can easily generalize to diseases that do not show strong patters because we focus on an individual by individual level.

Systems such as Flu Near You or OTHER ONE use self-reported symptoms to diagnose an individual also work from a bottom-up approach. These systems have the potential to be better than traditional surveillance systems because they update in near-real-time and can detect cases even when the user has not gone to their doctor. These systems require the user to sign up which allows for long term studies which are not normally able to be done with Tweets or search queries. However this reduces the number of users studied compared to datamining approaches. For example, Flu Near You had a total of 9,456 users report during the week ending 29 December 2013. PERSON et al. has shown a large drop out rate[] with only XX\% users participating for more than two weeks. While this amount of data is sufficient for many purposes, a system which is based on Twitter's XXX active users would open the door to novel questions.


%Digital epidemiology \(\to\) novel disease detection mechanisms.
%
%Validation of this idea is important, but not done.
%
%Pull med info of individuals professionally diagnosed with ILI and their twitter accts. Compare old methods. Suggest some new things.

We develop this such a system as follows. In section 3 we describe the collection of professional diagnosis of Twitter users and collect their Twitter information. In section 4 we consider extracting textual information from Tweets as a method for diagnosing influenza. In section 5 we consider anomalies in a user's Tweeting behavior as a signal for diagnosing influenza. In section 6 we extend these methods to other users on a persons social network to diagnose the original person. In section 7 we aggregate the results of the previous classifiers to develop a more accurate meta-classifier.

\section{Related Work}

People with issues \cite{Bodnar:2013we,Butler:2013uh,Lamb:2013to} also plos paper!

Most work to this point considers finding messages in tweets (i.e. ``I'm sick'') or in keyword frequencies. 

Keyword \cite{Culotta:2010hx,Goel:2010jf}

Tweet classification \cite{Culotta:2010hx,Lamb:2013to,Salathe:2011gr}

\section{Data Collection}
\subsection{Medical Records}
\subsection{Twitter Records}
We received a total of 119 user accounts for Twitter from the survey; 15 of which were discarded because the associated accounts were either non-existent, banned, or private. For each of the remaining 104 accounts, we pulled their profile information, their friends and followers information, their most recent 3000 tweets, and their friends profiles and tweets. Some users did not tweet during the month that they were sick; we kept those accounts as part of the control group. We were limited to the most recent 3000 tweets by Twitter's time line query, but this only effected two accounts -- both of which posted multiple times per hour and were thrown out because we could only look back a few days.

We collected data by calling the Twitter API on the user account that we queried the longest time ago. Tweets, profile and follower information queries have separate rate limits and were collected in parallel. The 104 seed accounts collected above were given higher priority over their friends and followers. In total, we collected 37,599 tweets from the seed accounts and 30,950,958 tweets from 913,082 accounts that they either followed or were followed by.

%select count(distinct(d_net.user)) from (select distinct(user) as user from tweets_network) as d_net left join tweets on d_net.user = tweets.user where tweets.user is null;

%\section{Signal Detection}
\section{Text Based Signals}

In this section, we consider diagnosis based on classifying an individual tweet's content as either about ILI or not. We begin by dividing the tweets into two sets: tweets that were posted the same month that a user was sick, and tweets that were posted other times. We find a total of 1609 tweets from 35 users in the first category.

First we go the route of defining a set of keywords that are positive signals of influenza. We chose \{flu, influenza, sick, cough, cold, medicine, fever\} as our set of keywords. Of these seven keywords, we find a significant effect in 6 of the keywords during months when the user had ILI. (See table \ref{tab:tweet_keyword_expert_results}). Additionally, we try algorithmically selecting keywords by first finding the 12,393 most common keywords in the data set.  We then rank them based off of information gain and choose the top 10, 100 or 1000 keywords from the list. In both of these cases, we preprocess the data by tokenizing the text on the characters ``.,;':"()?!'' - as well as spaces, tabs and line breaks - remove stop words\footnote{Stop words taken from Weka's stoplist version 3.7.10.}, perform Porter stemming \cite{Porter:1980dd,Willett:2006vb}  and convert the text to lower case. We then use the occurance or absence of these keywords as features for classification. We use naive bayes, random forest, J48, logistic regression and support vector machines to classify a user as being sick in a given month or not (see figure \ref{fig:roc_keyword}).



\begin{figure} [h]
\centering
\begin{subfigure}[b]{.2\textwidth}
\includegraphics[width=\textwidth]{figs/key_exp_roc.eps}
\end{subfigure}
\begin{subfigure}[b]{.2\textwidth}
\includegraphics[width=\textwidth]{figs/key_dm_roc.eps}
\end{subfigure}
\begin{subfigure}[b]{.45\textwidth}
\includegraphics[width=\textwidth]{figs/keyword_legend.eps}
\end{subfigure}
\caption{The ROC of classifiers that use hand chosen keywords (a) and algorithmically chosen keywords (b) to determine if an individual is ill. The top 10 (solid line), 100 (dashed line) and 1000 (dotted line) were selected as the features.}
\label{fig:roc_keyword}
\end{figure}



Additionally, we hand rate all 1609 tweets, that were posted by individuals during the time of their illness,  for information regarding the user's health. Additionally we sample a randomly selected set of 1609 tweets from times when the users did not have ILI as a control. We find 58 tweets from 17 (\(17/35 = 48.57\%\))  individuals in our study that are about the user being sick. We also find zero tweets about ILI during times when they did \textit{not} have ILI. While the use of a ``human'' classifier clearly does not scale, it allows for an approxamatly 100.0\% accurate classification. Since regular machine learning algorithms preform much worse than 100.0\% accuracy, the human classifier gives us an upper limit to the accuracy of  a health monitoring system based off of tweet classification . (See table \ref{tab:tweet_classified_confusion})

%\include{tables/keyword_expert_odds.tex}

\begin{table}
\centering
\begin{tabular}{|c|c|c|c|} \hline
Word& Total &Odds Ratio & Significance\ \\ \hline
\input{tables/keyword_expert_odds}
\end{tabular}
\caption{Keyword effects.}
\label{tab:tweet_keyword_expert_results}
\end{table}


\begin{table}
\centering
\begin{tabular}{|c|c|c|} \hline
Sick&Not Sick&\ \\ \hline
17 & 18 & Sick\\ \hline
0 & 66  & Not Sick\\
\hline\end{tabular}
\caption{Confusion matrix of a Tweet-Classification based diagnosis system. Rows are of true values, columns are of predicted values.}
\label{tab:tweet_classified_confusion}
\end{table}

\section{Frequency Based Signals}

We perform one-dimensional anomaly detection on each user's monthly tweeting rate as follows. First, we calculate the number of tweets in each month in the study period and discard any months where the user tweets less than ten times. This avoids issues caused by the user starting or stopping to use Twitter. We then calculate the z-score of the tweeting rate of the month that the user is ill by

\begin{equation}
z = \frac{|x - \bar{x}|}{\hat{s}}
\end{equation}

Where \(\bar{x}\) and \(\hat{s}\) are the estimated mean and standard deviation of the user's tweeting rate. \cite{Grubs:1969ab} We repeat this process for months when the user is not sick. We then decide that the user is sick if \(z > 1.411\) where \(1.411\) was chosen through leave one out cross validation. We find a significant difference between the z-scores for months when a user was had ILI and months when the user did not (\(p = 0.01303\), two-sample Kolmogorov-Smirnov test). Most of the time individuals are not sick (219 / 258 = 84.88\%), resulting in a highly biased sample. Thus we optimize based on the \(F_1\) score. The optimal z-score cutoff results in \(F_1= 35.0\%\). (See table \ref{tab:tweet_anomaly_confusion}.) 

%\begin{figure} %need to redo
%\centering
%\includegraphics[width=0.5\textwidth]{figs/meanFrequencies.eps}
%\caption{The frequency of tweeting behaviour of individuals in the months before, during and after an illness. Users significantly (check) decrease their rate of tweeting during the time that they had influenza. Dashed lines indicate the mean rate for the three months before / after the illness. (Todo: check significance)}
%\label{fig:mean_freq}
%\end{figure}

\begin{table}
\centering
\begin{tabular}{|c|c|c|} \hline
Sick&Not Sick&\ \\ \hline
14 & 25 & Sick\\ \hline
27 & 192 & Not Sick\\
\hline\end{tabular}
\caption{Confusion matrix of the classifier based on anomalous tweeting rates. Rows are of true values, columns are of predicted values.}
\label{tab:tweet_anomaly_confusion}
\end{table}

\section{Network Based Signals}

Preliminary idea. Cascade effects causing echoes on social network. Also consider friends becoming ill around same time. Check @ tag

%follower 12393
%friend 11595

\begin{figure} [h]
\centering
\begin{subfigure}[b]{.2\textwidth}
\includegraphics[width=\textwidth]{figs/followers_roc.eps}
\end{subfigure}
\begin{subfigure}[b]{.2\textwidth}
\includegraphics[width=\textwidth]{figs/friends_roc.eps}
\end{subfigure}
\begin{subfigure}[b]{.45\textwidth}
\includegraphics[width=\textwidth]{figs/keyword_legend.eps}
\end{subfigure}
\caption{The ROC of classifiers based off Tweets from (a) accounts that follow a user and (b) accounts that a user follows. Line coloring and style are equivalent to figure \ref{fig:roc_keyword}.}
\label{fig:roc_network}
\end{figure}

\section{Meta Classifier}

Combine features based off of previous signals, get something that's -- hopefully -- more accurate.

To this point, we have considered five approaches to detecting illness -- keyword detection, keyword mining, human classification, frequency-based anomaly detection and network based classifiers -- independently. Now we consider combining the results of the previous classifiers and develop a meta-classifier. (See figure \ref{fig:roc_meta}) Concretely, we begin by selecting the classifier from each approach that has the largest area under the ROC curve. Then we use....

\begin{figure} [h]
\centering
\begin{subfigure}[b]{.2\textwidth}
\includegraphics[width=\textwidth]{figs/meta_roc.eps}
\end{subfigure}
\begin{subfigure}[b]{.2\textwidth}
\includegraphics[width=\textwidth]{figs/meta_roc_final.eps}
\end{subfigure}
\caption{The accuracy of the previous classifiers (a) and the accuracy of various classifiers that use the previous classifier's results as features (b). }
\label{fig:roc_meta}
\end{figure}


\section{Discussion}

 \begin{table}
\centering
\begin{tabular}{|c|c|c|} \hline
Keyword&Ratio\ \\ \hline
flu &  34.424\\ \hline
health &  11.360\\ \hline
sick &  5.019\\ \hline
track & 10.952 \\ \hline
stud & 3.508 \\ \hline
asshol & 9.090 \\ \hline
ton & 9.090 \\ \hline
particip & 20.667 \\ \hline
salt & 20.667 \\ \hline
recov & 40.118 \\ \hline
fuck & 2.963 \\ \hline
sham & 13.64 \\ \hline
row & 10.180 \\ \hline
win & 2.947 \\ \hline
rt & 3.077 \\ \hline
walk & 3.077 \\ \hline
childr & 6.820 \\ \hline
incred & 6.820 \\ \hline
meal & 6.820 \\ \hline
longer &  6.820 \\ \hline
succes &  26.765 \\ \hline
accis & 26.765 \\ \hline
holida & 26.765 \\ \hline
luv & 26.765 \\ \hline
oblig & 26.765 \\ \hline
path & 26.764 \\ \hline
pract & 26.764 \\ \hline
prayer & 26.765 \\ \hline
reserv & 26.765 \\ \hline
riot & 26.765 \\ 
\hline\end{tabular}
\caption{The thirty keyword stems with the highest positive predictive power ranked by significance. Ratio is calculated as the rate of occurance when a user is sick over the rate when a user is not sick.}
\label{tab:thirty_best}
\end{table}

Comment on \(\sim\) 250 mill active T users \(\to\) 75 mill active US users, possibility of detecting \(\sim\) 10\% anual ILI rate, \(\sim\) half are detectable on twitter Twitter, so 12.5 mill cases as upper estimate.


In this paper, we have shown that it is possible to diagnose an individual based off of her social media data with high accuracy. Computation approaches to aid in disease diagnosis has been approached before[], however they have been developed with a medical setting in mind. That is, the problem addressed was ``can we diagnose an individual based off data gathered from medical tests run on her?'' instead of ``can we diagnose an individual solely based off of publically available social media data?''  While we focus on the relativly benign case of remotely reconstructing a confidental diagnosis of influenza, these methods could also be applied to stigmatized diseases, such as HIV, where being able to determine if an individual is HIV positive without her knowledge and with only her Twitter handle could result in serious social or economic effects.

While our system should be trusted more than one based simply off of aggregated tweets, it is more computationally intensive than simply pulling data from a keyword stream. These systems require the user to select a specific set of keywords before data collection can begin. Keywords representing symptoms such as ``flu'', ``cough'', ``sore throat'', and ``headache'' are often chosen[]. We suggest that the thirty\footnote{The Twitter API limits queries to thirty keywords.} keywords with the highest postivie predictive value (see table \ref{tab:thirty_best}) be chosen as the parameters for a keyword stream. In addition to keywords related to symptoms (e.g. ``flu'' or ``sick'') we also find keywords related to treatments (e.g. ``health'' or ``recovery'') and keywords related to negative mood (e.g. vulgarities) to be more commonly tweeted when a user is ill. 

\section{Conclusions}


%\begin{thebibliography}{1}
%\bibitem{Ford:1956vc}
%L. R. Ford and D. R. Fulkerson. \newblock{Maximal Flow through a Network}. \newblock{\em Canadian Journal of Mathematics}, 8(3):399-404, 1956.
%\end{thebibliography}



%@article{Ford:1956vc,
%author = {Ford, L R and Fulkerson, D R},
%title = {{Maximal Flow through a Network.}},
%journal = {Canadian Journal of Mathematics},
%year = {1956},
%pages = {399--404}
%}


%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{library}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns

\balancecolumns
% That's all folks!
\end{document}
